{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Notebook 2 - Generando texto con LSTM.ipynb","provenance":[{"file_id":"1QTYek5FX1TZ_DXezpfhXZz2A8Jk4DP7G","timestamp":1605520203451},{"file_id":"1lEN90XmbO30NBsuz5Vaktl99wltY3yv6","timestamp":1605520141181},{"file_id":"1jfb-NB4ILkwqgLVRuqmRYAtFaStPkyWA","timestamp":1559150674713}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"G7ZM6m97oI7X"},"source":["# **Notebook 2 - Generando texto con LSTMs.**\n","\n","\n","*   Recuerda que puedes consultar la documentación sobre una función escribiendo **?** justo después de la función: *Ejemplo: np.maximum?*\n","*   Puedes ejecutar el contenido de una celda con el atajo de teclado **CTRL+ENTER**\n","*   Utiliza **TAB** cada vez que quieras autocompletar una llamada a una función.\n","*   Puedes ejecutar instrucciones de bash directamente desde el notebook usando **!** : *Ejemplo: !pip install tensorflow*\n","*   Recuerda que Google es tu amigo, y saber buscar la información en las documentaciones de las librerías es muy importante.\n","*   Una solución correcta no es la que funciona sino la que se entiende!\n","*   No dudes en preguntar cualquier duda al profesor que lleva todo el día dando la turra."]},{"cell_type":"markdown","metadata":{"id":"9A69_TMBaMY3"},"source":["## 1. Hoy vamos a generar '''_._._._._._._._._._.'''\n","\n","- **¡Tokeniza tu texto!** - Utiliza la función *Tokenizer()* de Keras para convertir tu texto a vectores de etiqueta numérica. Observa el contenido del objeto ***tokenizer*** para ver qué información te aporta. De ahí, imprime los índices que se han generado para cada una de las palabras. ¿Qué ocurre cuando decodificamos una palabra que no aparece en nuestro vocabulario? ¿Son todas las palabras en nuestro diccionario cómo  esperamos que sean, o hace falta preprocesar y filtrar algunas palabras?  **Compruébalo!**\n","\n","```\n","['Con', 'diez', 'cañones', ...] -----> [12, 1, 23, ...]\n","```\n","\n","- **¡Crea tu dataset!** - A continuación toca generar tus variables de entrada y salida. Tus datos deberá de representar lo que esperamos predecir para el número de palabras dadas como entrada. Si de entrada sólo miramos 1 palabra para hacer la predicción (e.g. *X0 = ['Con'] ; Y0 = ['diez']*), se dice que estamos trabajando con 2-grama (un *bigrama*). Por ahora lo haremos así. Crea todos los posibles *bigramas*, y guarda en tu matriz **X** las palabras de entrada, y en la **Y** las palabras de salida. Recuerda que los índices de la salida deben de estar correctamente codificados (**One-Hot Encoded**) ¿Y los de entrada si usamos una capa de Embeddings?..\n","\n","```\n","X : [12, 1, 23, ...] -----> Y: [1, 23, 4, ...]\n","```\n","\n","  - **¡Crea tu modelo!** -  Vamos a crear un modelo sencillito que haga uso de lo visto hoy en clases. Tu modelo consistirá de una capa de *tf.keras.layers.Embeddings()* inicial. ¿Para qué sirve? A partir de ahí añade una capa *tf.keras.layers.LSTM()* y finalmente una capa densa con la capa de activación correspondiente.\n","\n","- **¡Genera texto!** - Utiliza tu modelo para generar texto. Dale una palabra de tu vocabulario como comienzo y a partir de ahí utiliza cada texto de salida generado como input de la próxima iteración, así hasta obtener el texto de la longitud que quieras. ¿Qué te produce? ¿Observas algún fenómeno extraño? ¿Por qué?\n","\n","- **¡Entiende lo que has hecho!** - Consulta en la documentación de Tensorflow las dimensiones de lo que estás utilizando; intenta mejorar el resultado del entrenamiento e investiga cómo podríamos mejorar el modelo. En las siguientes sesiones iremos añadiendo nuevos elementos al trabajo.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"QuJlgj3_X0pt","executionInfo":{"status":"ok","timestamp":1605694073049,"user_tz":-60,"elapsed":2250,"user":{"displayName":"Carlos Santana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVvecaHB34gYjkoFZQot-Hnc3Xf1MVl3zUO4FoNL8=s64","userId":"06972008324074016783"}}},"source":["from tensorflow.keras import *\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.preprocessing.text import *\n","\n","import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"v1PP_5rKTmGh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605694074523,"user_tz":-60,"elapsed":1467,"user":{"displayName":"Carlos Santana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVvecaHB34gYjkoFZQot-Hnc3Xf1MVl3zUO4FoNL8=s64","userId":"06972008324074016783"}},"outputId":"faec7b93-74c4-4974-ee60-e525d1ee2de8"},"source":["!wget https://raw.githubusercontent.com/busiris2014/7506Condor1C2014/master/datos2011/trunk/libros/J.K.%20Rowling%20-%20Harry%20Potter%203%20-%20El%20Prisionero%20de%20Azkaban.txt\n","\n","with open('/content/J.K. Rowling - Harry Potter 3 - El Prisionero de Azkaban.txt', 'r') as file:\n","    data = file.read().replace('\\n', ' ')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-11-18 10:07:53--  https://raw.githubusercontent.com/busiris2014/7506Condor1C2014/master/datos2011/trunk/libros/J.K.%20Rowling%20-%20Harry%20Potter%203%20-%20El%20Prisionero%20de%20Azkaban.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 671651 (656K) [text/plain]\n","Saving to: ‘J.K. Rowling - Harry Potter 3 - El Prisionero de Azkaban.txt’\n","\n","J.K. Rowling - Harr 100%[===================>] 655.91K  --.-KB/s    in 0.02s   \n","\n","2020-11-18 10:07:54 (26.4 MB/s) - ‘J.K. Rowling - Harry Potter 3 - El Prisionero de Azkaban.txt’ saved [671651/671651]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y0GQpXKKDQ9t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605616519127,"user_tz":-60,"elapsed":5997,"user":{"displayName":"Carlos Santana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVvecaHB34gYjkoFZQot-Hnc3Xf1MVl3zUO4FoNL8=s64","userId":"06972008324074016783"}},"outputId":"b2707779-6d55-4cd9-e85a-783c9fa89620"},"source":["!wget https://gist.githubusercontent.com/phillipj/4944029/raw/75ba2243dd5ec2875f629bf5d79f6c1e4b5a8b46/alice_in_wonderland.txt\n","\n","with open('/content/alice_in_wonderland.txt', 'r') as file:\n","    data = file.read().replace('\\n', ' ')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-11-17 12:35:16--  https://gist.githubusercontent.com/phillipj/4944029/raw/75ba2243dd5ec2875f629bf5d79f6c1e4b5a8b46/alice_in_wonderland.txt\n","Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 148574 (145K) [text/plain]\n","Saving to: ‘alice_in_wonderland.txt’\n","\n","alice_in_wonderland 100%[===================>] 145.09K  --.-KB/s    in 0.04s   \n","\n","2020-11-17 12:35:17 (3.72 MB/s) - ‘alice_in_wonderland.txt’ saved [148574/148574]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XLJc5oKf1QkR","executionInfo":{"status":"ok","timestamp":1605694208117,"user_tz":-60,"elapsed":909,"user":{"displayName":"Carlos Santana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVvecaHB34gYjkoFZQot-Hnc3Xf1MVl3zUO4FoNL8=s64","userId":"06972008324074016783"}}},"source":["Tokenizer?"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"9MVpes6sXV_I","executionInfo":{"status":"ok","timestamp":1605694346201,"user_tz":-60,"elapsed":791,"user":{"displayName":"Carlos Santana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVvecaHB34gYjkoFZQot-Hnc3Xf1MVl3zUO4FoNL8=s64","userId":"06972008324074016783"}}},"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","max_vocab = 5000\n","\n","tokenizer = Tokenizer(num_words=max_vocab)\n","\n","# Añadimos al filtro el siguiente caracter, que se comprueba está presente en\n","# muchas palabras del vocabulario.\n","tokenizer.filters  = '\"#$%&()*+,-./:;<=>@[\\\\]^_`{|}~\\t\\n©\\x92\\x93\\x94\\x97«»'\n","# Configuramos al tokenizador.\n","tokenizer.fit_on_texts([data])\n","# Y codificamos nuestro texto\n","encoded = tokenizer.texts_to_sequences(data.split(\".\"))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"OzcIpDiWdWqE","executionInfo":{"status":"ok","timestamp":1605694364311,"user_tz":-60,"elapsed":926,"user":{"displayName":"Carlos Santana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVvecaHB34gYjkoFZQot-Hnc3Xf1MVl3zUO4FoNL8=s64","userId":"06972008324074016783"}}},"source":["full_vocab_size = len(tokenizer.word_index) + 1\n","\n","if not max_vocab:\n","  max_vocab = full_vocab_size\n","\n","print('Tamaño del vocabulario:', full_vocab_size)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"AMxHUCYkmf9x","executionInfo":{"status":"ok","timestamp":1605694367473,"user_tz":-60,"elapsed":699,"user":{"displayName":"Carlos Santana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVvecaHB34gYjkoFZQot-Hnc3Xf1MVl3zUO4FoNL8=s64","userId":"06972008324074016783"}}},"source":["def decode_sequence(sequence):\n","  return \" \".join([tokenizer.index_word.get(w) for w in sequence])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tt7TFVPleMly","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605694995391,"user_tz":-60,"elapsed":924,"user":{"displayName":"Carlos Santana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVvecaHB34gYjkoFZQot-Hnc3Xf1MVl3zUO4FoNL8=s64","userId":"06972008324074016783"}},"outputId":"bccda5f3-750b-4eb2-88d4-101ce1662e38"},"source":["# Número de palabras en la frase a seleccionar.\n","n_tokens = 10\n","\n","sequences = [] # Listado de secuencias a guardar.\n","\n","# Para cada una de las frases del texto...\n","for sequence in encoded:\n","  # ...si la secuencia es mayor al número de tokens que queremos.\n","\tif len(sequence) >= n_tokens:\n","\t\t\t# ...nos desplazamos por la frase seleccionando subsecuencias.\n","\t\t\tfor i in range(n_tokens, len(sequence)):\n","\t\t\t\t# seleccionamos la subsecuencia.\n","\t\t\t\tseq = sequence[i - n_tokens:i+1]\n","\t\t\t\t# y la guardamos en nuestro listado.\n","\t\t\t\tsequences.append(seq)\n","\n","sequences = np.array(sequences)\n","print('Secuencias totales:', len(sequences))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Secuencias totales: 34852\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qs021MulePqU","executionInfo":{"status":"ok","timestamp":1605695099188,"user_tz":-60,"elapsed":1330,"user":{"displayName":"Carlos Santana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVvecaHB34gYjkoFZQot-Hnc3Xf1MVl3zUO4FoNL8=s64","userId":"06972008324074016783"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","# Seleccionamos los n-1 primeros tokens como input, y el último como output.\n","X, Y = sequences[:,:-1], sequences[:,-1:]\n","# Convertirmos el output a One-hot Encoding.\n","Y = tokenizer.sequences_to_matrix(Y)\n","# Generamos una partición de entrenamiento y test.\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"VKhiWzekzmYc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605695100987,"user_tz":-60,"elapsed":818,"user":{"displayName":"Carlos Santana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVvecaHB34gYjkoFZQot-Hnc3Xf1MVl3zUO4FoNL8=s64","userId":"06972008324074016783"}},"outputId":"b5fa4480-e89b-4bcf-bad9-6b5740e0d845"},"source":["# Método para decodificar las frases tokenizadas.\n","def decode_sentence(sentence):\n","  return \" \".join([tokenizer.index_word.get(w) for w in sentence])\n","\n","# Seleccionamos unos cuantos inputs/ouputs para visualizarlos.\n","for i in np.random.choice(len(X_test), 5):\n","  print('Input:', decode_sequence(X_test[i]), '\\nOutput:', tokenizer.index_word.get(np.argmax(Y_test[i])), '\\n ---------')"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Input: largos y días las tiendas y comiendo bajo de brillantes \n","Output: colores \n"," ---------\n","Input: ahora mismo por la tía petunia que era huesuda y \n","Output: tenía \n"," ---------\n","Input: hermione que había estado en el de hagrid dejó escapar \n","Output: un \n"," ---------\n","Input: lo han dicho en la porque fudge quería mantenerlo en \n","Output: pero \n"," ---------\n","Input: dejara manchas de tinta en las sábanas los dursley no \n","Output: tendrían \n"," ---------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BAorQg8cErJT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605697665133,"user_tz":-60,"elapsed":85029,"user":{"displayName":"Carlos Santana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVvecaHB34gYjkoFZQot-Hnc3Xf1MVl3zUO4FoNL8=s64","userId":"06972008324074016783"}},"outputId":"4ae9a82c-94f0-4cfc-8290-6714d3e75372"},"source":["from tensorflow.keras import Model, Sequential\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import *\n","\n","model = Sequential()\n","\n","embed_size = 100\n","\n","# Capa de Entrada.\n","model.add(Input(shape=(n_tokens,), dtype=\"int32\"))\n","# Capa de Embeddings.\n","model.add(Embedding(max_vocab, embed_size))\n","# Capa de LSTM.\n","model.add(Bidirectional(LSTM(units=128)))\n","model.add(Dropout(rate=0.2))\n","# Capa de Salida.\n","model.add(Dense(max_vocab, activation='softmax'))\n","\n","callbacks = [EarlyStopping(patience=3, monitor='val_loss')]\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='acc')\n","\n","model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=32, epochs=10, callbacks=callbacks)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","730/730 [==============================] - 12s 17ms/step - loss: 6.5198 - acc: 0.0645 - val_loss: 6.2432 - val_acc: 0.0692\n","Epoch 2/10\n","730/730 [==============================] - 11s 16ms/step - loss: 5.9361 - acc: 0.0878 - val_loss: 6.0270 - val_acc: 0.0962\n","Epoch 3/10\n","730/730 [==============================] - 12s 16ms/step - loss: 5.5442 - acc: 0.1093 - val_loss: 5.9197 - val_acc: 0.1119\n","Epoch 4/10\n","730/730 [==============================] - 11s 16ms/step - loss: 5.1650 - acc: 0.1322 - val_loss: 5.8910 - val_acc: 0.1242\n","Epoch 5/10\n","730/730 [==============================] - 11s 15ms/step - loss: 4.7662 - acc: 0.1570 - val_loss: 5.9439 - val_acc: 0.1242\n","Epoch 6/10\n","730/730 [==============================] - 11s 16ms/step - loss: 4.3458 - acc: 0.1834 - val_loss: 6.0739 - val_acc: 0.1249\n","Epoch 7/10\n","730/730 [==============================] - 11s 16ms/step - loss: 3.9000 - acc: 0.2208 - val_loss: 6.2390 - val_acc: 0.1198\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fd0769d8550>"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"GcLAKcmdLHwZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605697703444,"user_tz":-60,"elapsed":1298,"user":{"displayName":"Carlos Santana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVvecaHB34gYjkoFZQot-Hnc3Xf1MVl3zUO4FoNL8=s64","userId":"06972008324074016783"}},"outputId":"6730a1d1-bf44-40d5-c768-0de04636e42c"},"source":["print('Input:',  decode_sentence(X_test[60]))\n","print('Output:', tokenizer.index_word.get(np.argmax(model.predict(X_test[60:61]))))"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Input: nuestro breve encuentro fui yo quien te envió la saeta\n","Output: de\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uXSNuSQIE0Oz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605697772969,"user_tz":-60,"elapsed":3366,"user":{"displayName":"Carlos Santana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVvecaHB34gYjkoFZQot-Hnc3Xf1MVl3zUO4FoNL8=s64","userId":"06972008324074016783"}},"outputId":"f9b1129f-1ce4-4542-ce2e-3cf99c75dd34"},"source":["text = \" \".join([tokenizer.index_word.get(w) for w in X_test[5]])\n","print(text)\n","\n","words = text.split(\" \")\n","\n","for i in range(50):\n","  # Obtenemos la distribución de predicciones.\n","  tokns = tokenizer.texts_to_sequences([words])\n","  probs = model.predict(tokns)[0]\n","  # Generamos una muestra de dicha distribución para sacar la nueva palabra.\n","  yhat  = tokenizer.index_word.get(np.random.choice(len(probs), p=probs))\n","  # La añadimos al texto.\n","  text += \" \" + yhat\n","  # Sacamos las nuevas palabras de input.\n","  words = text.split(\" \")[- n_tokens:]\n","\n","print(text)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["piensa que con su muerte quien tú sabes volvería al\n","piensa que con su muerte quien tú sabes volvería al de las peligrosas a recuperar el moverse el retrato y y black a la estación a el ató dando estaba bajara en una mano peluda y durmiendo de una la varita de hacerse y sin encontrara en una gata con los pesados y quedó ningún últimos maleta noticia y que\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"04NLfL_9SmAB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605618001859,"user_tz":-60,"elapsed":1217,"user":{"displayName":"Carlos Santana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVvecaHB34gYjkoFZQot-Hnc3Xf1MVl3zUO4FoNL8=s64","userId":"06972008324074016783"}},"outputId":"3a92ec02-4280-416f-fea8-1e4d311775cb"},"source":["np.random.choice(len(probs))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4762"]},"metadata":{"tags":[]},"execution_count":39}]}]}